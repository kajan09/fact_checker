# Reelâ€‘Factâ€‘Checker

**Automatically transcribe Instagram Reels, extract factual claims, search for supporting evidence, and return a scored truthfulness reportâ€¯â€”â€¯all from a single POST request.**

---

## âœ¨ Features

| Stage                         | What it does                                                   | Key deps                            |
| ----------------------------- | -------------------------------------------------------------- | ----------------------------------- |
| 1. **Download**               | Grabs the Reel video & metadata via *Instaloader*              | `instaloader`                       |
| 2. **Audio extraction**       | Converts MP4 â†’ WAV                                             | `moviepy`, `ffmpeg-python`          |
| 3. **Transcription**          | Generates an accurate transcript with Whisper                  | `openai-whisper`, `torch`, `ffmpeg` |
| 4. **Statement slicing**      | Breaks the transcript into discrete factual claims             | `llamaâ€‘cppâ€‘python`                  |
| 5. **Query generation**       | Produces webâ€‘search queries tailored to each claim             | LLaMAâ€‘powered prompt                |
| 6. **Web retrieval**          | Fetches candidate articles & videos                            | `requests`, (any search API)        |
| 7. **Evidence summarisation** | Distils retrieved content down to the relevant passages        | LLaMA prompt                        |
| 8. **Truthfulness scoring**   | Judges each claim *True / False / Mixed* & assigns a 0â€‘1 score | LLaMA prompt                        |

> All steps live in \`\` files so you can run them independently or as a full pipeline.

---

## ğŸ—‚ï¸ Repository layout

```
â”œâ”€â”€ app/                  # Core source
â”‚   â”œâ”€â”€ main.py           # FastAPI entryâ€‘point
â”‚   â”œâ”€â”€ pipeline.py       # Orchestrates the eight steps
â”‚   â”œâ”€â”€ reel_utils.py     # Helpers for download & media handling
â”‚   â”œâ”€â”€ step_1_audio_to_transcript.py
â”‚   â”œâ”€â”€ â€¦ step_8_statement_to_score.py
â”‚   â”œâ”€â”€ *.wav             # Test fixtures
â”‚   â””â”€â”€ json_example.json # Sample output
â”œâ”€â”€ reelâ€‘toâ€‘wav/          # Oneâ€‘off converter script
â”œâ”€â”€ archive_old_tests/    # Experimental notebooks & tests
â”œâ”€â”€ requirements.txt      # Python deps
â””â”€â”€ README.md             # â† you are here
```

---

## ğŸš€ QuickÂ start

### 1. Prerequisites

* **Pythonâ€¯â‰¥â€¯3.9** (tested on 3.11)
* **FFmpeg** in your `$PATH`
* **Ollama** running locally with a LLaMAâ€‘3/8B (or bigger) model pulled
* A **GPU** (optional but ğŸï¸ fast) â€” Whisper & LLaMA both detect CUDA automatically

```bash
# Ubuntu example
sudo apt update && sudo apt install ffmpeg git
curl -fsSL https://ollama.ai/install.sh | sh  # installs & launches the Ollama daemon
ollama pull llama3:8b                         # download a model once
```

### 2. Install Python deps

```bash
git clone https://github.com/yourâ€‘org/reelâ€‘factâ€‘checker.git
cd reelâ€‘factâ€‘checker
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

### 3. Run the API

```bash
# inside the repo root
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

Now open [http://localhost:8000/docs](http://localhost:8000/docs) to explore the interactive OpenAPI docs.

---

## ğŸ–‡ï¸ Example request

```bash
curl -X POST http://localhost:8000/process \
  -H "Content-Type: application/json" \
  -d '{
        "url": "https://www.instagram.com/reel/DJE5V6_RHvu/",
        "mock": false
      }'
```

```jsonc
{
  "id": "12c5c52fâ€‘4ad3â€‘45daâ€‘8b31â€‘e24996c0a293",
  "transcript": "â€¦full transcriptâ€¦",
  "statements": [
    {
      "text": "The Eiffel Tower grows up to 15Â cm during summer.",
      "truthness": "true",
      "score": 0.94,
      "evidence": [
        "https://www.bbc.com/news/worldâ€‘europeâ€‘â€¦",
        "https://en.wikipedia.org/wiki/Eiffel_Tower"
      ],
      "summary": "Thermal expansion of the iron causes a measurable height increase of ~15Â cm on hot days."
    },
    â€¦
  ]
}
```

Set `"mock": true` to skip the network calls and return the **sample output** in `app/json_example.json` â€” perfect for local UI prototyping.

---

## âš™ï¸ Environment variables

| Name              | Default                  | Purpose                            |
| ----------------- | ------------------------ | ---------------------------------- |
| `OLLAMA_BASE_URL` | `http://localhost:11434` | Where to reach the Ollama REST API |
| `LLAMA_MODEL`     | `llama3:8b`              | Model tag to use for all prompts   |
| `MAX_TOKENS`      | `2048`                   | Cap for generation length          |

> Add a `.env` file or export vars in your shell. `pipeline.py` reads them with `os.getenv()`.

---

## ğŸ› ï¸ Developing & testing

1. **Run a single step** for debugging:

   ```bash
   python -m app.step_3_statement_to_query app/json_example.json
   ```
2. **Unit tests** live next to their subject files. Execute everything with:

   ```bash
   pytest -q
   ```
3. **BlackÂ +Â ruff** keep the code tidy:

   ```bash
   ruff check . && black --check .
   ```

---

## ğŸ—ºï¸ Pipeline diagram

```mermaid
graph TD
    A[Instagram Reel URL] -->|instaloader| B[MP4]
    B -->|moviepy / ffmpeg| C[WAV]
    C -->|Whisper| D[Transcript]
    D -->|LLaMA prompt| E[Factual statements]
    E --> F[Search queries]
    F --> G[Web results]
    G --> H[Evidence summary]
    H --> I[Truthfulness + score]
    I --> J[JSON response]
```

## ğŸ—ºï¸ Pipeline diagram

![alt text](docs/pipeline_setup.excalidraw.png "Title")


---

## ğŸ“¦ Docker (optional)

A minimal production image is provided. Build & run:

```bash
docker build -t reelâ€‘factâ€‘checker .
docker run -p 8000:8000 -e OLLAMA_BASE_URL=http://host.docker.internal:11434 reelâ€‘factâ€‘checker
```

The container bundles Whisperâ€™s English model and your requirements, but youâ€™ll still need an Ollama server (or any LLM endpoint) reachable from the host.

---

## ğŸ“ License

Distributed under the **MIT License** â€” see `LICENSE` for details.

---

## ğŸ¤ Contributing

Pull requests are very welcome! For major changes, please open an issue first to discuss what you would like to change.

1. Fork â–¶ï¸ branch â–¶ï¸ commit (+â€¯tests) â–¶ï¸ PR.
2. Make sure `ruff` & `black` pass.
3. One feature per PR.

---

## ğŸ™ Acknowledgements

* [OpenAI Whisper](https://github.com/openai/whisper)
* [LLaMAâ€‘cpp](https://github.com/ggerganov/llama.cpp)
* [Instaloader](https://instaloader.github.io/)
* [MoviePy](https://zulko.github.io/moviepy/)
* And every OSS maintainer who made this pipeline possible â™¥ï¸
